{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoNewsMiner - Geocoding *ChroniclItaly*\n",
    "\n",
    "This [Jupyter notebook](https://jupyter.org/) implements the data processing and geocoding for the GeoNewsMiner (GNM) project. GNM is an interactive tool that maps and visualises geographical references in historical newspapers. As a use case, we used Italian immigrant newspapers published in the United States from 1898 to 1920, as collected in the corpus [*ChroniclItaly*](https://public.yoda.uu.nl/i-lab/UU01/T4YMOW.html) (Viola 2018). The corpus was previously tagged for entities using a sequence tagging tool ([Riedl and Padó 2018](https://www.aclweb.org/anthology/P18-2020.pdf)). This tagged version of *ChroniclItaly* is [*ChroniclItaly 2.0*](https://public.yoda.uu.nl/i-lab/UU01/4MECRO.html) and it is available as an open access resource. The overarching goal of this project is to offer new perspectives on the geographies of the past. Methodologically, we extracted from the corpus the references to place names, quantified them, geo-coded them, and plotted them on a map. \n",
    "\n",
    "Please read the [README](https://github.com/lorellav/GeoNewsMiner) for more information and context on this project.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Environment set-up](#Environment-set-up)\n",
    "2. [Data pre-processing](#Data-pre-processing)\n",
    "3. [Geocoding](#Geocoding)\n",
    "4. [Fixing geocoding errors](#Fixing-geocoding-errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment set-up\n",
    "\n",
    "The code in this notebook is written in Python 3. If you are new to Python, please install Anaconda from https://www.anaconda.com/distribution/. The list of dependencies required to run this notebook correctly can be found in [requirements.txt](https://github.com/lorellav/GeoNewsMiner/blob/master/requirements.txt). The dependencies can be installed with [Anaconda Navigator](https://docs.anaconda.com/anaconda/navigator/) or with the command `pip install -r requirements.txt` from the command line (CMD.exe or terminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# internal dependencies\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# external depencies\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folders, variables and settings\n",
    "\n",
    "First, we initialise the structure of our repository. Executing the next cell sets the definitions to the folders and files in the project. We use the `/output` folder for all files generated during the execution of this notebook. All results are reproducible. The `/data` folder is used for all static, non-changing files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the data folder and files\n",
    "data_folder = \"data\"\n",
    "\n",
    "fp_metadata = os.path.join(data_folder, 'ChroniclItaly_title_lccn.csv')\n",
    "\n",
    "# location of the output folder and files\n",
    "output_folder = \"output\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "fp_stats = os.path.join(output_folder, 'ChroniclItaly_stats_per_doc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "GNM extracts the geographical entities from *ChroniclItaly* as they were found using an advanced machine-learning tool, [sequence tagging](https://github.com/riedlma/sequence_tagging#download-models-and-embeddings) (Riedl and Padó 2018) that implements [Tensorflow](https://www.tensorflow.org/). In this step, geographical locations are extracted from the tagged results. For more information on the sequence tagging, please refer to the [README](https://github.com/lorellav/GeoNewsMiner#sequence-tagging). \n",
    "\n",
    "The data output by the tagger has the format as found below. The first column is the input word, the second column specifies the pre-processed, lower-cased word, the third column contains a flag, whether the word has been known during training (KNOWN) or not (UNKNOWN). If labels are assigned to the input file, these will appear in the third column. The last column contains the predicted tags. The no-entity tag is `O`. Because some entities (like Stati Uniti) have multiple words, the tagging scheme distinguishes between the beginning (tag `B-...`) or the inside of an entity (tag `I-...`). Locations can be tagged with `LOC` of `GPE`. \n",
    "\n",
    "```sh\n",
    "il         il         KNOWN   O       O\n",
    "principio  principio  KNOWN   O       O\n",
    "delle      delle      KNOWN   O       O\n",
    "ostilità   ostilità   KNOWN   O       O\n",
    "fra        fra        KNOWN   O       O\n",
    "la         la         KNOWN   O       O\n",
    "Spagna     spagna     KNOWN   O       B-GPE\n",
    "e          e          KNOWN   O       O\n",
    "gli        gli        KNOWN   O       O\n",
    "Stati      stati      KNOWN   O       B-GPE\n",
    "Uniti      uniti      KNOWN   O       I-GPE\n",
    ".          .          KNOWN   O       O\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell implements the functions used to group the tags with multiple words. The function `combine_tags()` accepts a list with pairs with the word and the tag, such as: `[(\"spagna\", \"B-GPE\"), (\"e\", \"\"), (\"gli\", \"\"), (\"stata\", \"B-GPE\"), (\"uniti\", \"I-GPE\"), (\".\", \"\")]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This defines the function to combine tags that start with a B tag and \n",
    "# are followed by I tags. \n",
    "\n",
    "def _endswidth_list(s, list_s_end):\n",
    "    \"\"\"Check if string ends with a value in the list\"\"\"\n",
    "    for s_end in list_s_end:\n",
    "        if s and s.endswith(s_end):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def combine_tags(words_with_tags, tags=[\"LOC\", \"GPE\"]):\n",
    "    \"\"\"Combine tags is they consist of multiple words\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for token, label in words_with_tags:\n",
    "              \n",
    "        # continue if label is not in the list\n",
    "        if not _endswidth_list(label, tags):        \n",
    "            continue\n",
    "            \n",
    "        # split the document in a prefix (I or B) and a tag\n",
    "        prefix, tag = label.split(\"-\")\n",
    "        \n",
    "        # if I, append to previous\n",
    "        if prefix == \"I\":\n",
    "            try: \n",
    "                results[-1] = (results[-1][0] + \" \" + token, results[-1][1])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        else:\n",
    "            results.append((token, tag))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File by file processing\n",
    "\n",
    "Each file in *ChroniclItaly* has a structured name: `2012271201_1903-08-08_ed-1_seq-1_ocr.txt`, `2012271201_1903-08-15_ed-1_seq-1_ocr.txt`, `2012271201_1903-08-22_ed-1_seq-1_ocr.txt`. \n",
    "\n",
    "The first part of the file name is the LCCN identifier (in this case 2012271201) of each newspaper's title. The second part of the file name contains the date of publication (for example '1903-06-06'). The rest of the metadata in the file name is not relevant for this analysis and is ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>LCCN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>La sentinella del West Virginia</td>\n",
       "      <td>sn86092310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>L'Italia</td>\n",
       "      <td>sn85066408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Cronaca sovversiva. (Barre, Vt.)</td>\n",
       "      <td>2012271201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>La libera parola</td>\n",
       "      <td>sn85055164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The patriot</td>\n",
       "      <td>sn85054967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>La ragione</td>\n",
       "      <td>sn84037024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>La rassegna</td>\n",
       "      <td>sn84037025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title        LCCN\n",
       "0   La sentinella del West Virginia  sn86092310\n",
       "1                          L'Italia  sn85066408\n",
       "2  Cronaca sovversiva. (Barre, Vt.)  2012271201\n",
       "3                  La libera parola  sn85055164\n",
       "4                       The patriot  sn85054967\n",
       "5                        La ragione  sn84037024\n",
       "6                       La rassegna  sn84037025"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the meta data with the Titles of the papers\n",
    "meta_data = pd.read_csv(fp_metadata)\n",
    "meta_data['LCCN'] = meta_data['LCCN'].str.replace(' ', '')  # remove space in sn numbers\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files in *ChroniclItaly 2.0* have the format as described in Section [Data-pre-processing](#Data-pre-processing). The tags `LOC` and `GPE`, relevant for the analysis, are combined and counted. The column `location` stores all the entities tagged as location`LOC`, the column `freq` shows the corresponding frequency of occurrence, the column `word_count` contains a count of the words in the file. All other columns are repeated metadata from the file name. \n",
    "\n",
    "For example, the output of the file `2012271201_1903-08-15_ed-1_seq-1_ocr.txt` is shown below. The location \"amsterdam\" was mentioned once in the document and \"australia\" was mentioned 3 times. Moreover, the document contains 1,695 words. \n",
    "\n",
    "|        LCCN | Title                            | date                |   year | location   |   freq |   word_count | loc/gpe   | filename                                 |\n",
    "| -----------:|:---------------------------------|:--------------------|-------:|:-----------|-------:|-------------:|:----------|:-----------------------------------------|\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | amsterdam  |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | australia  |      3 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | belgio     |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | bruxelles  |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | ispagna    |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | italia     |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | melbourne  |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | olanda     |      2 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | parma      |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | rima       |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "|  2012271201 | Cronaca sovversiva. (Barre, Vt.) | 1903-08-15 00:00:00 |   1903 | torino     |      1 |         1695 | GPE       | 2012271201_1903-08-15_ed-1_seq-1_ocr.txt |\n",
    "\n",
    "The following code iterates over all files and generates data frames like the one above. All the data frames are then combined in `df_locations`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct a generator on input files\n",
    "input_files = Path(data_folder).glob(str(Path(\"**\",\"*.txt\")))\n",
    "\n",
    "results = []\n",
    "\n",
    "# reading the raw_data files: iterate over all txt files in ./data directory\n",
    "for index, data_fp in tqdm(enumerate(input_files)):\n",
    "    \n",
    "    # extract sn number and date from the filename\n",
    "    sn, raw_date, _, _, _ = str(data_fp.stem).split('_')\n",
    "    \n",
    "    # read the ocr file into pandas dataframe\n",
    "    df_data = pd.read_csv(\n",
    "        data_fp, \n",
    "        sep='\\t', \n",
    "        names=['token', 'token_lowercase', 'col2', 'col3', 'tag', 'col5']\n",
    "    )\n",
    "    \n",
    "    # combine the tokens\n",
    "    location_tag_tuples = combine_tags(\n",
    "        [tuple(x) for x in df_data[['token', 'tag']].values],\n",
    "        tags=[\"LOC\", \"GPE\"]\n",
    "    )\n",
    "    \n",
    "    df_location_tag = pd.DataFrame(location_tag_tuples, columns=['location', 'loc/gpe'])\n",
    "    \n",
    "    # some cleaning and preprocessing \n",
    "    df_location_tag['location'] = df_location_tag['location'].str.lower()\n",
    "    df_location_tag['location'] = df_location_tag['location'] \\\n",
    "        .str.normalize('NFKD') \\\n",
    "        .str.encode('ascii', errors='ignore') \\\n",
    "        .str.decode('utf-8') \\\n",
    "        .str.replace(r\"[^a-z\\'\\\"\\-\\s]\", \"\") \\\n",
    "        .str.strip()\n",
    "    \n",
    "    # group and count the tokens\n",
    "    df_location_tag_count = df_location_tag \\\n",
    "        .groupby(['location', 'loc/gpe']) \\\n",
    "        .size() \\\n",
    "        .rename(\"freq\") \\\n",
    "        .reset_index()\n",
    "            \n",
    "    # merge gpes and locs and add additional data\n",
    "    df_location_tag_count['LCCN'] = sn\n",
    "    df_location_tag_count['filename'] = str(data_fp).split('/')[-1]\n",
    "    df_location_tag_count['date'] = raw_date\n",
    "    df_location_tag_count['date'] = pd.to_datetime(df_location_tag_count['date'])\n",
    "    df_location_tag_count['year'] = df_location_tag_count['date'].dt.year\n",
    "        \n",
    "    # merge meta data\n",
    "    df_location_tag_count = df_location_tag_count.merge(meta_data, on=\"LCCN\", how=\"left\")\n",
    "    \n",
    "    # compute the number of words in the document\n",
    "    df_location_tag_count['word_count'] = df_data['token'].str.match(r'\\w+').sum()\n",
    "    \n",
    "    # append df to results\n",
    "    results.append(df_location_tag_count)\n",
    "\n",
    "df_locations = pd.concat(results) \n",
    "\n",
    "# column order and sorting \n",
    "df_locations = df_locations[['LCCN', 'Title', 'date', 'year', 'location', 'freq', 'word_count', 'loc/gpe', 'filename']]\n",
    "df_locations.sort_values(by='date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are loaded in `ChroniclItaly_stats_per_doc.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to csv file\n",
    "df_locations.to_csv(fp_stats, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from file (start with the script from this point if file is available)\n",
    "df_locations = pd.read_csv(fp_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results, frequencies and stats\n",
    "\n",
    "The following is the results of the process of location extraction. The following lines of code allow users to carry out some preliminary explorations of the results such as looking at the top 20 most frequently mentioned locations, the number of unique locations, the total number of geographical references, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "italia           3424\n",
       "roma             3386\n",
       "new york         2858\n",
       "stati uniti      2396\n",
       "francia          2362\n",
       "parigi           2206\n",
       "san francisco    2012\n",
       "londra           1998\n",
       "russia           1938\n",
       "washington       1830\n",
       "america          1826\n",
       "germania         1822\n",
       "napoli           1751\n",
       "milano           1643\n",
       "genova           1353\n",
       "inghilterra      1204\n",
       "europa           1196\n",
       "pietroburgo      1182\n",
       "berlino          1173\n",
       "torino           1126\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the top 20 locations in terms of \"document frequency\"\n",
    "df_locations['location'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31579"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of unique locations (without cleaning or geocoding)\n",
    "len(df_locations['location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214110"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of locations found across all articles\n",
    "df_locations['freq'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the number of times the same location in mentioned in the frontpage\n",
    "fig = df_locations['freq'].plot.hist(\n",
    "    bins=35,\n",
    "    title=\"Number of mentions to the same location in one page\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding \n",
    "\n",
    "In this step, the locations found in the dataset are geocoded. Geocoding provides (standardised) information like a place identifier and WGS84 (World Geodetic System) coordinates. To perform the geocoding, we use the Google Maps Geocoding API. For costs please refer to https://developers.google.com/maps/documentation/geocoding/usage-and-billing. \n",
    "\n",
    "In order to perform geocoding, users must have an API key. The API key is a unique identifier, a 40-character long string that is used to authenticate requests associated with a project. To get an API key, visit the [Google Cloud Platform Console](https://cloud.google.com/console/google/maps-apis/overview). \n",
    "\n",
    "Geocoding with Google is a two-stage process. First, Google Geocoding API provides users with a Place ID for each location. The Place ID uniquely identifies a place as it is stored in the Google Places database and on Google Maps. Because the language of the dataset is Italian, the language of the API was set to Italian. It was found that setting the API language as the language of the data-set improves the accuracy of the geocoding results. At the same time, however, the results are also returned in Italian. In order to have the results returned in Enlgish, only the Place ID was extracted in this first stage. Once the Place ID was received, it was possible to use the Google Geocoding API to perform *reverse geocoding*, that is to obtain all the details for the location in English (e.g., geo-coordinates, administrative level). In this way, the results are dispalyed in English thus making the GNM App more user-friendly. \n",
    "\n",
    "The following example outlines the two-stage process with a simple code example. \n",
    "```\n",
    "x_loc = gc_client.geocode(\"roma\", language=\"it\")\n",
    "pprint(x_loc)\n",
    "print()\n",
    "y_loc = gc_client.reverse_geocode(x_loc[0]['place_id'], language=\"en\")\n",
    "pprint(y_loc)\n",
    "```\n",
    "\n",
    "In addition to the geo-coordinates, Google also provides additional details, such as the tag *type[]*. Understanding the *type[]* of a location is important because it shows why Google has provided given geo-coordinates to a location. Some of these geo-coordinates may have been \"misinterpreted\" and therefore the field *type[]* should be checked. \"Misinterpretations\" may happen especially when working with historical data. Because the Google Places database stores places based on a contemporary world map, the locations in a historical dataset may have changed name or may no longer exist. Moreover, categories such as country, city, region, municipality, etc. which Google uses to determine the location *type[]* are highly dependent on the location itself and consequently certain categories may not apply or they may change from place to place. Read more about the *type* [here]:(https://developers.google.com/maps/documentation/geocoding/intro). The most common types in our dataset are given by:\n",
    "\n",
    "> - **political**: indicates a political entity. Usually, this type indicates a polygon of some civil administration.\n",
    "- **country**: indicates the national political entity, and it is typically the highest order type returned by the Geocoder.\n",
    "- **administrative_area_level_1**: indicates a first-order civil entity below the country level. Within the United States, these administrative levels are States. Not all countries have this administrative level. In most cases, administrative_area_level_1 short names will closely match ISO 3166-2 subdivisions and other widely circulated lists; however, this is not guaranteed as our geocoding results are based on a variety of signals and location data.\n",
    "- **administrative_area_level_2**: indicates a second-order civil entity below the country level. Within the United States, these administrative levels are counties. Not all nations exhibit these administrative levels.\n",
    "- **colloquial_area**: indicates a commonly-used alternative name for the entity.\n",
    "- **locality indicates**: indicates an incorporated city or town political entity.\n",
    "- **sublocality**: indicates a first-order civil entity below a locality. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost estimation\n",
    "\n",
    "To avoid incurring in high costs, we estimated the costs as it is shown in the cells below. This can be done by separating the unique locations  from the frequency counts in the aggregated file (`df_locations`). The frequency count is multiplied for the price of 5.00 USD per 1000 requests.\n",
    "\n",
    "We also noticed that in our dataset, the highest number of incorrectly tagged entities occurred for the least mentioned locations, probably due to OCR mistakes in the original data. Therefore, we performed the geocoding only for the locations that occurred >8 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique locations: 31579\n",
      "Estimated Google geocoding costs: 157.895\n"
     ]
    }
   ],
   "source": [
    "unique_locations = df_locations['location'].unique()\n",
    "\n",
    "print(\"The number of unique locations:\", len(unique_locations))\n",
    "print(\"Estimated Google geocoding costs:\", len(unique_locations)*5/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of selected locations: 1368\n",
      "Estimated Google geocoding costs: 6.84\n"
     ]
    }
   ],
   "source": [
    "place_counts = df_locations. \\\n",
    "    groupby('location'). \\\n",
    "    agg({'freq': 'sum', 'Title': 'nunique'}). \\\n",
    "    rename(columns={'freq': 'occurs', 'Title': 'volumes'}). \\\n",
    "    sort_values([\"occurs\", \"volumes\"], ascending=False)\n",
    "\n",
    "selected_locations = place_counts[(place_counts['occurs']>=8)]\n",
    "\n",
    "print(\"The number of interesting locations:\", len(selected_locations))\n",
    "print(\"Estimated Google geocoding costs:\", len(selected_locations)*5/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Google Maps API\n",
    "\n",
    "In order to perform the geocoding with Google Maps API, users must have an API key. The API key is a unique identifier, a 40-character long string that is used to authenticate requests associated with a project. To get an API key, visit the [Google Cloud Platform Console](https://cloud.google.com/console/google/maps-apis/overview). The key should be stored in a secure location/file on your device. The following code shows how to request a key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import the package googlemaps (maintained by Google)\n",
    "import googlemaps\n",
    "\n",
    "# set the maximum query rate\n",
    "gc_rate  = 50\n",
    "\n",
    "# get the API key from file \n",
    "api_key_file = os.path.expanduser(\n",
    "    os.path.join('~', 'Credentials', 'googlemaps.txt')\n",
    ")\n",
    "\n",
    "with open(api_key_file) as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "# Initialise the Google Maps client\n",
    "gc_client = googlemaps.Client(key=api_key, queries_per_second=gc_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the geocoding process, it may be useful to define some functions as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns and order of variables to export\n",
    "export_columns = [\n",
    "    'location', 'placeid', 'formatted_address', 'location_type', 'continent', \n",
    "    'colloquial_area', 'country', 'country_short', 'admin_1', 'admin_2', 'locality', \n",
    "    'natural_feature', 'point_of_interest', 'lat', 'lon', 'partial'\n",
    "]\n",
    "\n",
    "def get_placeid(string, api_client=gc_client, language=None):\n",
    "    \"\"\"Get place id for location string\"\"\"\n",
    "    try:\n",
    "        place = api_client.geocode(string, language=language)\n",
    "        try:\n",
    "            place_id = place[0]['place_id']\n",
    "        except Exception:\n",
    "            place_id = None\n",
    "    except:\n",
    "        place_id = None\n",
    "    return place_id\n",
    "\n",
    "\n",
    "def lookup_placeid(placeid, api_client=gc_client):\n",
    "    \"\"\"Retrieve detailed information for placeid\"\"\"\n",
    "\n",
    "    try:\n",
    "        data = gc_client.reverse_geocode(placeid)\n",
    "    except:\n",
    "        return {} # Problem with geocoding API call\n",
    "\n",
    "    \n",
    "    result = {\n",
    "        'formatted_address' : None,\n",
    "        'location_type' : None,\n",
    "        'country' : None,\n",
    "        'country_short' : None,\n",
    "        'admin_1' : None,\n",
    "        'admin_2' : None,\n",
    "        'locality' : None,\n",
    "        'colloquial_area' : None,\n",
    "        'continent' : None,\n",
    "        'natural_feature' : None,\n",
    "        'point_of_interest' : None,\n",
    "        'lat' : None,\n",
    "        'lon' : None,\n",
    "        'partial' : None,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        data = data[0]  # first result\n",
    "        result['formatted_address'] = data['formatted_address']\n",
    "        result['location_type'] = \"+\".join(data['types'])\n",
    "        result['lat'] = data['geometry']['location']['lat']\n",
    "        result['lon'] = data['geometry']['location']['lng']\n",
    "        try:\n",
    "            result['partial'] = result['partial_match']\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        print(\"Problem with geocoding %s\" % (placeid))\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        for address in data['address_components']:\n",
    "            comp_type = address['types'][0]  # first types\n",
    "            if comp_type == 'locality':\n",
    "                result['locality'] = address['long_name']\n",
    "            if comp_type == 'country':\n",
    "                result['country'] = address['long_name']\n",
    "                result['country_short'] = address['short_name']\n",
    "            if comp_type == 'administrative_area_level_1':\n",
    "                result['admin_1'] = address['long_name']\n",
    "            if comp_type == 'administrative_area_level_2':\n",
    "                result['admin_2'] = address['long_name']\n",
    "            if comp_type == 'colloquial_area':\n",
    "                result['colloquial_area'] = address['long_name']\n",
    "            if comp_type == 'natural_feature':\n",
    "                result['natural_feature'] = address['long_name']\n",
    "            if comp_type == 'point_of_interest':\n",
    "                result['point_of_interest'] = address['long_name']\n",
    "            if comp_type == 'continent':\n",
    "                result['continent'] = address['long_name']\n",
    "    except:\n",
    "        return {}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, the selected locations (with a frequency of at least 8) are queried with the API. The language for the place id extraction is set to 'it' ('italian'). This provides better geocoding results. The `lookup_placeid()` function queries the variables like 'formatted_address', 'location_type', 'continent', 'colloquial_area', 'country', 'country_short', 'admin_1', 'admin_2', 'locality', 'natural_feature', 'point_of_interest', 'lat' and 'lon'. The result of the geocoding is stored in a datetime stamped file in the output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result file with the location-coordinates (datetime coded)\n",
    "fp_geodata_base = os.path.join(\n",
    "    output_folder, \n",
    "    \"output_\" +\n",
    "    dt.datetime.now().strftime(\"%Y%H%d_%I%M%S\") +\n",
    "    \"_geocoding\")\n",
    "\n",
    "geo_codes = []\n",
    "\n",
    "for loc in tqdm(selected_locations.index):\n",
    "\n",
    "    result_loc = {\"location\": loc}\n",
    "\n",
    "    # get the placeid\n",
    "    placeid = get_placeid(loc, language=\"it\")\n",
    "    result_loc[\"placeid\"] = placeid\n",
    "\n",
    "    # if placeid, lookup geodata\n",
    "    if placeid:\n",
    "        geo_code = lookup_placeid(placeid)\n",
    "        result_loc.update(geo_code)\n",
    "\n",
    "    geo_codes.append(result_loc)\n",
    "\n",
    "geo_codes_df = pd.DataFrame(geo_codes).set_index(\"location\")\n",
    "geo_codes_df = geo_codes_df[export_columns[1:]]\n",
    "geo_codes_df.to_csv(fp_geodata_base + \".csv\")\n",
    "geo_codes_df.to_excel(fp_geodata_base + \".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing geocoding errors\n",
    "\n",
    "The geocoding results may contain errors. Errors \n",
    "can be the result of mistakes in the geocoding algorithm, the lack of important\n",
    "information or OCR problems. \n",
    "Correcting these errors is necessary to have a valid and clean dataset. These mistakes can be corrected manually \n",
    "in the `.xslx` file. To speed up the process, we developed a\n",
    "function that finds the correct location and copies it \n",
    "to the clipboard immediately. \n",
    "\n",
    "##### Example\n",
    "\n",
    "The location 'Zara' is a good example. The geocoding algorithm of Google\n",
    "identified it as a clothing store in the USA. Given the historical context of the study, this is obviously a mistake. \n",
    "The mentions refers to the Province of Zara - today Zadar - in Croatia which used to be a territory of the Kingdom of Italy from 1918 to 1947. \n",
    "Therefore, we corrected the location and asked the geocoding\n",
    "algorithm to geocode Zara as \"Zadar Croatia\". \n",
    "\n",
    "```\n",
    "> manual_loopup(\"Zadar Croatia\")\n",
    "```\n",
    "\n",
    "|location    |   placeid    |  formatted_address  | location  | placeid | formatted_address  |location_type |continent |colloquial_area  |country | admin_1 | admin_2 | locality | natural_feature |  point_of_interest    |    lat    |    lon | partial  |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| zadar croatia  | ChIJj7jA0mL6YUcRhAf0Exw-MhI   | Zadar, Croatia  | locality+political   |   None        |    None  | Croatia  |  None  |  None   | Zadar      |      None      |        None | 44.119371 | 15.231365 |   False  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_loopup(str_location, str_orginal_location=None, decimal=\",\", verbosity=0):\n",
    "    \"\"\"Function to do manual lookup and copy to clipboard\"\"\"\n",
    "\n",
    "    result = {\n",
    "        \"location\": str_location\n",
    "    }\n",
    "\n",
    "    # get the place id\n",
    "    plid = get_placeid(str_location, language=\"it\")\n",
    "    result[\"placeid\"] = plid\n",
    "\n",
    "    # if there is a place id, get more data. \n",
    "    if plid:\n",
    "        geo_code = lookup_placeid(plid)\n",
    "        result.update(geo_code)\n",
    "\n",
    "    geo_codes_df_correction = pd.DataFrame([result])\n",
    "    geo_codes_df_correction = geo_codes_df_correction[export_columns]\n",
    "    \n",
    "    # print the output\n",
    "    if verbosity:\n",
    "        print(geo_codes_df_correction.T)\n",
    "        \n",
    "    # copy to clipboard (drop location)\n",
    "    geo_codes_df_correction. \\\n",
    "        drop(\"location\", axis=1). \\\n",
    "        to_clipboard(\n",
    "            header=False, \n",
    "            index=False,\n",
    "            decimal=decimal\n",
    "    )\n",
    "    \n",
    "    # return frame\n",
    "    return geo_codes_df_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_loopup(\"zadar croatia\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
